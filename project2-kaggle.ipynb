{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":66638,"databundleVersionId":7378729,"sourceType":"competition"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <font style=\"color:blue\">Project 2: Kaggle Competition - Classification</font>\n\n#### Maximum Points: 100\n\n<div>\n    <table>\n        <tr><td><h3>Sr. no.</h3></td> <td><h3>Section</h3></td> <td><h3>Points</h3></td> </tr>\n        <tr><td><h3>1</h3></td> <td><h3>Data Loader</h3></td> <td><h3>10</h3></td> </tr>\n        <tr><td><h3>2</h3></td> <td><h3>Configuration</h3></td> <td><h3>5</h3></td> </tr>\n        <tr><td><h3>3</h3></td> <td><h3>Evaluation Metric</h3></td> <td><h3>10</h3></td> </tr>\n        <tr><td><h3>4</h3></td> <td><h3>Train and Validation</h3></td> <td><h3>5</h3></td> </tr>\n        <tr><td><h3>5</h3></td> <td><h3>Model</h3></td> <td><h3>5</h3></td> </tr>\n        <tr><td><h3>6</h3></td> <td><h3>Utils</h3></td> <td><h3>5</h3></td> </tr>\n        <tr><td><h3>7</h3></td> <td><h3>Experiment</h3></td><td><h3>5</h3></td> </tr>\n        <tr><td><h3>8</h3></td> <td><h3>TensorBoard Dev Scalars Log Link</h3></td> <td><h3>5</h3></td> </tr>\n        <tr><td><h3>9</h3></td> <td><h3>Kaggle Profile Link</h3></td> <td><h3>50</h3></td> </tr>\n    </table>\n</div>\n","metadata":{}},{"cell_type":"markdown","source":"## <font style=\"color:green\">1. Data Loader [10 Points]</font>\n\nIn this section, you have to write a class or methods, which will be used to get training and validation data loader.\n\nYou need to write a custom dataset class to load data.\n\n**Note; There is   no separate validation data. , You will thus have to create your own validation set, by dividing the train data into train and validation data. Usually, we do 80:20 ratio for train and validation, respectively.**\n\n\nFor example:\n\n```python\nclass KenyanFood13Dataset(Dataset):\n    \"\"\"\n    \n    \"\"\"\n    \n    def __init__(self, *args):\n    ....\n    ...\n    \n    def __getitem__(self, idx):\n    ...\n    ...\n    \n\n```\n\n\n```python\ndef get_data(args1, *args):\n    ....\n    ....\n    return train_loader, test_loader\n```","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport shutil\nimport os\nimport sys\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom torchvision import transforms\nfrom PIL import Image","metadata":{"execution":{"iopub.status.busy":"2024-07-30T17:55:12.782381Z","iopub.execute_input":"2024-07-30T17:55:12.782789Z","iopub.status.idle":"2024-07-30T17:55:16.562902Z","shell.execute_reply.started":"2024-07-30T17:55:12.782758Z","shell.execute_reply":"2024-07-30T17:55:16.561947Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"\n\n# Load your dataset\ndata = pd.read_csv(r'/kaggle/input/opencv-pytorch-classification-project-2/train.csv')\n\n# Define the split ratio (e.g., 80% training and 20% validation)\ntrain_size = 0.8\n\n# Split the data\ntrain_data, validation_data = train_test_split(data, train_size=train_size, random_state=42)\n\n# Save the split datasets into new CSV files\ntrain_data.to_csv('train_data.csv', index=False)\nvalidation_data.to_csv('validation_data.csv', index=False)\n\nprint(len(train_data))\n\nprint(len(validation_data))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create new directory for training set\nif not os.path.exists('training'):\n    os.mkdir('training')\n\n# Read your train CSV file for lable\nlabels=pd.read_csv(r'/kaggle/working/train_data.csv')\n\n#DataFrame 'labels' with columns 'id' and 'class'\n\n\n# Set the base directory where your images are located\nbase_image_dir = '/kaggle/input/opencv-pytorch-classification-project-2/images/images/'\ndst_dir=r\"/kaggle/working/training\"\n# Iterate over each row in the labels DataFrame\nfor _, row in labels.iterrows():\n    image_id = row['id']\n    class_label = str(row['class'])\n\n    # Construct source and destination paths\n    src_path = os.path.join(base_image_dir, f'{image_id}.jpg')\n    dst_path = os.path.join(dst_dir, class_label, f'{image_id}.jpg')\n\n    try:\n        # Check if the source file exists\n        if os.path.exists(src_path):\n            # Create the destination directory if needed\n            os.makedirs(os.path.dirname(dst_path), exist_ok=True)\n            shutil.copy(src_path, dst_path)\n            print(f\"Successfully copied {src_path} to {dst_path}\")\n        else:\n            print(f\"Source file {src_path} does not exist.\")\n    except Exception as e:\n        print(f\"Error copying {src_path} to {dst_path}: {e}\")\n\nprint(\"All images processed!\")\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create new directory for training set\nif not os.path.exists('validation'):\n    os.mkdir('validation')\n\nval_lables=pd.read_csv(r'/kaggle/working/validation_data.csv')\n\n\"\"\"# Create class directories\nfor _, label in val_lables.iterrows():\n    class_folder = str(label['class'])\n    if not os.path.exists(class_folder):\n        os.mkdir(class_folder)\"\"\"\n\n# Set the base directory where your images are located\nbase_image_dir = '/kaggle/input/opencv-pytorch-classification-project-2/images/images/'\ndst_dir=r\"/kaggle/working/validation\"\n# Iterate over each row in the labels DataFrame\nfor _, row in labels.iterrows():\n    image_id = row['id']\n    class_label = str(row['class'])\n\n    # Construct source and destination paths\n    src_path = os.path.join(base_image_dir, f'{image_id}.jpg')\n    dst_path = os.path.join(dst_dir, class_label, f'{image_id}.jpg')\n\n    try:\n        # Check if the source file exists\n        if os.path.exists(src_path):\n            # Create the destination directory if needed\n            os.makedirs(os.path.dirname(dst_path), exist_ok=True)\n            shutil.copy(src_path, dst_path)\n            print(f\"Successfully copied {src_path} to {dst_path}\")\n        else:\n            print(f\"Source file {src_path} does not exist.\")\n    except Exception as e:\n        print(f\"Error copying {src_path} to {dst_path}: {e}\")\n\nprint(\"All images processed!\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read your test CSV file for geting test image set\ntest_img=pd.read_csv(r'/kaggle/input/opencv-pytorch-classification-project-2/test.csv')\n\n#create new directory for test set\nif not os.path.exists('test'):\n    os.mkdir('test')\n# Set the base directory where your images are located\nbase_image_dir = '/kaggle/input/opencv-pytorch-classification-project-2/images/images/'\ntest_dst=r\"/kaggle/working/test\"#destination for test images\n\n# Iterate over each row in the labels DataFrame\nfor _, row in test_img.iterrows():\n    image_id = row['id']\n    \n# Construct source and destination paths\n    src_path = os.path.join(base_image_dir, f'{image_id}.jpg')\n    dst_path = os.path.join(test_dst, f'{image_id}.jpg')\n    \n    try:\n        # Check if the source file exists\n        if os.path.exists(src_path):\n            # Create the destination directory if needed\n            #os.makedirs(os.path.dirname(dst_path), exist_ok=True)\n            shutil.copy(src_path, dst_path)\n            print(f\"Successfully copied {src_path} to {dst_path}\")\n        else:\n            print(f\"Source file {src_path} does not exist.\")\n    except Exception as e:\n        print(f\"Error copying {src_path} to {dst_path}: {e}\")\n\nprint(\"All images processed!\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\n\nimport time\nfrom typing import Iterable\nfrom dataclasses import dataclass\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torchvision import datasets, transforms, models\nfrom torch.optim import lr_scheduler\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom PIL import Image","metadata":{"execution":{"iopub.status.busy":"2024-07-30T17:55:24.257179Z","iopub.execute_input":"2024-07-30T17:55:24.257734Z","iopub.status.idle":"2024-07-30T17:55:24.266754Z","shell.execute_reply.started":"2024-07-30T17:55:24.257702Z","shell.execute_reply":"2024-07-30T17:55:24.265714Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import os\nimport pandas as pd\nfrom PIL import Image\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nimport cv2\nclass KenyanFood13Dataset(Dataset):\n    \"\"\"\n    Custom Dataset for Kenyan Food Images with 13 classes.\n    \n    \"\"\"\n    \n\n    def __init__(self, dataframe,data_root,is_train, transform=None):\n        \"\"\"\n        Initializes the dataset.\n\n        Parameters:\n        - data_root (str): Path to the dataset directory.\n        - transform (callable, optional): Optional transform to be applied on a sample.\n        \"\"\"\n        self.dataframe= dataframe\n        self.data_root = data_root\n        self.transform = transform\n        self.is_train= is_train\n          \n              \n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, idx):\n        img_path, label = self.dataframe.iloc[idx]\n        image = Image.open(img_path).convert(\"RGB\")\n\n        if self.transform:\n            image = self.transform(image)\n        \n        return image, label\n\n\n            \n        \n        image=Image.fromarray(image1)\n        if self.is_train:\n            lable_key=self.dataframe.iloc[idx,1]\n            lable=torch.tensor(str(lable_key))\n        else:\n            lable=torch.tensor(1)\n        if self.transform :\n            image=self.transform(image)\n\n        return image, label\n   ","metadata":{"execution":{"iopub.status.busy":"2024-07-30T18:07:54.904050Z","iopub.execute_input":"2024-07-30T18:07:54.904446Z","iopub.status.idle":"2024-07-30T18:07:54.914595Z","shell.execute_reply.started":"2024-07-30T18:07:54.904415Z","shell.execute_reply":"2024-07-30T18:07:54.913555Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"    \n    mean=(0.5773, 0.4627, 0.3468)\n    std=(0.2387, 0.2470, 0.2473)\n    train_transform=  transforms.Compose([\n    \n            transforms.Resize(256),\n            transforms.CenterCrop(224),\n            transforms.ColorJitter(brightness = 0.6),\n            transforms.RandomChoice([\n                transforms.RandomHorizontalFlip(),\n                transforms.RandomVerticalFlip(),\n                transforms.RandomRotation(20, fill=(0,0,0)),\n                transforms.RandomCrop(224, padding=4),\n                transforms.RandomAffine(30, translate=(0.3,0.3),\n                                        scale=(0.8, 1.2), shear=None)\n            ]),\n\n            transforms.ToTensor(),\n            transforms.Normalize(mean, std)\n        \n        ])\n    \n    \n    valid_transform =transforms.Compose([\n    \n            transforms.Resize(224),\n            transforms.ToTensor(),\n            transforms.Normalize(mean, std)\n         ])\n    \n\n        \n    \n\n    ","metadata":{"execution":{"iopub.status.busy":"2024-07-30T18:07:54.927841Z","iopub.execute_input":"2024-07-30T18:07:54.928113Z","iopub.status.idle":"2024-07-30T18:07:54.936573Z","shell.execute_reply.started":"2024-07-30T18:07:54.928089Z","shell.execute_reply":"2024-07-30T18:07:54.935567Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"    def custom_collate_fn(batch):\n        images, labels = zip(*batch)\n        images = torch.stack(images, dim=0)\n        labels = torch.tensor(labels)\n        return images, labels","metadata":{"execution":{"iopub.status.busy":"2024-07-30T18:07:54.947724Z","iopub.execute_input":"2024-07-30T18:07:54.947990Z","iopub.status.idle":"2024-07-30T18:07:54.952636Z","shell.execute_reply.started":"2024-07-30T18:07:54.947967Z","shell.execute_reply":"2024-07-30T18:07:54.951598Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"\n\n   \ntrain_dataroot=r\"/kaggle/working/training\"\ntrain_dataframe=pd.read_csv('/kaggle/working/train_data.csv')\ntrain_dataset=KenyanFood13Dataset(train_dataframe,train_dataroot,is_train=True,transform=train_transform)\n \nval_dataroot =r\"/kaggle/working/validation\" \nval_dataframe=pd.read_csv('/kaggle/working/validation_data.csv')\nval_dataset =KenyanFood13Dataset(val_dataframe,val_dataroot,is_train=True,transform=train_transform)  \ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True,collate_fn=custom_collate_fn)\nval_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=False,collate_fn=custom_collate_fn)\n    \nprint(len(train_loader))\nprint(len(val_loader))\n\n\n    \n   ","metadata":{"execution":{"iopub.status.busy":"2024-07-30T18:07:54.962802Z","iopub.execute_input":"2024-07-30T18:07:54.963066Z","iopub.status.idle":"2024-07-30T18:07:54.976493Z","shell.execute_reply.started":"2024-07-30T18:07:54.963044Z","shell.execute_reply":"2024-07-30T18:07:54.975492Z"},"trusted":true},"execution_count":77,"outputs":[{"name":"stdout","text":"164\n41\n","output_type":"stream"}]},{"cell_type":"code","source":"print(len (train_loader))#number of batches for training\nprint(len(val_loader ))#number of batches for validation \n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-07-30T18:07:54.987862Z","iopub.execute_input":"2024-07-30T18:07:54.988109Z","iopub.status.idle":"2024-07-30T18:07:54.992703Z","shell.execute_reply.started":"2024-07-30T18:07:54.988088Z","shell.execute_reply":"2024-07-30T18:07:54.991866Z"},"trusted":true},"execution_count":78,"outputs":[{"name":"stdout","text":"164\n41\n","output_type":"stream"}]},{"cell_type":"code","source":"@dataclass\nclass SystemConfiguration:\n    '''\n    Describes the common system setting needed for reproducible training\n    '''\n    seed: int = 21  # seed number to set the state of all random number generators\n    cudnn_benchmark_enabled: bool = True  # enable CuDNN benchmark for the sake of performance\n    cudnn_deterministic: bool = True  # make cudnn deterministic (reproducible training)","metadata":{"execution":{"iopub.status.busy":"2024-07-30T18:07:55.012754Z","iopub.execute_input":"2024-07-30T18:07:55.013024Z","iopub.status.idle":"2024-07-30T18:07:55.017827Z","shell.execute_reply.started":"2024-07-30T18:07:55.013001Z","shell.execute_reply":"2024-07-30T18:07:55.016990Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"markdown","source":"## <font style=\"color:green\">2. Configuration [5 Points]</font>\n\n**Define your configuration here.**\n\nFor example:\n\n\n```python\n@dataclass\nclass TrainingConfiguration:\n    '''\n    Describes configuration of the training process\n    '''\n    batch_size: int = 10 \n    epochs_count: int = 50  \n    init_learning_rate: float = 0.1  # initial learning rate for lr scheduler\n    log_interval: int = 5  \n    test_interval: int = 1  \n    data_root: str = \"/kaggle/input/opencv-pytorch-classification-project-2/\" \n    num_workers: int = 2  \n    device: str = 'cuda'  \n    \n```","metadata":{}},{"cell_type":"code","source":"@dataclass\nclass TrainingConfiguration:\n    '''\n    Describes configuration of the training process\n    '''\n    batch_size: int = 10\n    epochs_count: int = 100\n    init_learning_rate: float = 0.0001  # initial learning rate for lr scheduler\n    log_interval: int = 5\n    test_interval: int = 1\n    data_root: str =r\"/kaggle/input/opencv-pytorch-classification-project-2\" \n    num_workers: int = 2\n    device: str = 'cuda'\n    decay_rate:float=0.2","metadata":{"execution":{"iopub.status.busy":"2024-07-30T18:07:55.047826Z","iopub.execute_input":"2024-07-30T18:07:55.048074Z","iopub.status.idle":"2024-07-30T18:07:55.053925Z","shell.execute_reply.started":"2024-07-30T18:07:55.048054Z","shell.execute_reply":"2024-07-30T18:07:55.052950Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"def setup_system(system_config: SystemConfiguration) -> None:\n    torch.manual_seed(system_config.seed)\n    if torch.cuda.is_available():\n        torch.backends.cudnn_benchmark_enabled = system_config.cudnn_benchmark_enabled\n        torch.backends.cudnn.deterministic = system_config.cudnn_deterministic","metadata":{"execution":{"iopub.status.busy":"2024-07-30T18:07:55.078004Z","iopub.execute_input":"2024-07-30T18:07:55.078277Z","iopub.status.idle":"2024-07-30T18:07:55.082966Z","shell.execute_reply.started":"2024-07-30T18:07:55.078254Z","shell.execute_reply":"2024-07-30T18:07:55.082035Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"def train(\n    train_config: TrainingConfiguration, model: nn.Module, optimizer: torch.optim.Optimizer,\n    train_loader: torch.utils.data.DataLoader, epoch_idx: int\n) -> None:\n\n    # change model in training mood\n    model.train()\n\n    # to get batch loss\n    batch_loss = np.array([])\n\n    # to get batch accuracy\n    batch_acc = np.array([])\n\n    for batch_idx, (data, target) in enumerate(train_loader):\n\n        # clone target\n        indx_target = target.clone()\n        # send data to device (its is medatory if GPU has to be used)\n        data = data.to(train_config.device)\n        # send target to device\n        target = target.to(train_config.device)\n\n        # reset parameters gradient to zero\n        optimizer.zero_grad()\n\n        # forward pass to the model\n        output = model(data)\n\n        # cross entropy loss\n        loss = F.cross_entropy(output, target)\n\n        # find gradients w.r.t training parameters\n        loss.backward()\n        # Update parameters using gardients\n        optimizer.step()\n\n        batch_loss = np.append(batch_loss, [loss.item()])\n\n        # Score to probability using softmax\n        prob = F.softmax(output, dim=1)\n\n        # get the index of the max probability\n        pred = prob.data.max(dim=1)[1]\n\n        # correct prediction\n        correct = pred.cpu().eq(indx_target).sum()\n\n        # accuracy\n        acc = float(correct) / float(len(data))\n\n        batch_acc = np.append(batch_acc, [acc])\n\n    epoch_loss = batch_loss.mean()\n    epoch_acc = batch_acc.mean()\n    print('Epoch: {} \\nTrain Loss: {:.6f} Acc: {:.4f}'.format(epoch_idx, epoch_loss, epoch_acc))\n    return epoch_loss, epoch_acc","metadata":{"execution":{"iopub.status.busy":"2024-07-30T18:07:55.104228Z","iopub.execute_input":"2024-07-30T18:07:55.104494Z","iopub.status.idle":"2024-07-30T18:07:55.114217Z","shell.execute_reply.started":"2024-07-30T18:07:55.104472Z","shell.execute_reply":"2024-07-30T18:07:55.113340Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"def validate(\n    train_config: TrainingConfiguration,\n    model: nn.Module,\n    test_loader: torch.utils.data.DataLoader,\n) -> float:\n    #\n    model.eval()\n    test_loss = 0\n    count_corect_predictions = 0\n    for data, target in val_loader:\n        \n        data = data.to(train_config.device)\n\n        target = target.to(train_config.device)\n\n        with torch.no_grad():\n            output = model(data)\n\n        # add loss for each mini batch\n        test_loss += F.cross_entropy(output, target).item()\n\n        # Score to probability using softmax\n        prob = F.softmax(output, dim=1)\n\n        # get the index of the max probability\n        pred = prob.data.max(dim=1)[1]\n\n        # add correct prediction count\n        count_corect_predictions += pred.cpu().eq(indx_target).sum()\n\n    # average over number of mini-batches\n    test_loss = test_loss / len(val_loader)\n\n    # average over number of dataset\n    accuracy = 100. * count_corect_predictions / len(val_loader.dataset)\n\n    print(\n        '\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n            test_loss, count_corect_predictions, len(val_loader.dataset), accuracy\n        )\n    )\n\n    return test_loss, accuracy/100.0","metadata":{"execution":{"iopub.status.busy":"2024-07-30T18:07:55.167972Z","iopub.execute_input":"2024-07-30T18:07:55.168234Z","iopub.status.idle":"2024-07-30T18:07:55.176227Z","shell.execute_reply.started":"2024-07-30T18:07:55.168212Z","shell.execute_reply":"2024-07-30T18:07:55.175316Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"def save_model(model, device, model_dir='models', model_file_name='KenyanFood13.pt'):\n\n\n    if not os.path.exists(model_dir):\n        os.makedirs(model_dir)\n\n    model_path = os.path.join(model_dir, model_file_name)\n\n    # make sure you transfer the model to cpu.\n    if device == 'cuda':\n        model.to('cpu')\n\n    # save the state_dict\n    torch.save(model.state_dict(), model_path)\n\n    if device == 'cuda':\n        model.to('cuda')\n\n    return","metadata":{"execution":{"iopub.status.busy":"2024-07-30T18:07:55.207925Z","iopub.execute_input":"2024-07-30T18:07:55.208192Z","iopub.status.idle":"2024-07-30T18:07:55.214467Z","shell.execute_reply.started":"2024-07-30T18:07:55.208169Z","shell.execute_reply":"2024-07-30T18:07:55.213604Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"def load_model(model, model_dir='models', model_file_name='KenyanFood13.pt'):\n    model_path = os.path.join(model_dir, model_file_name)\n\n    # loading the model and getting model parameters by using load_state_dict\n    model.load_state_dict(torch.load(model_path))\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-07-30T18:07:55.247854Z","iopub.execute_input":"2024-07-30T18:07:55.248099Z","iopub.status.idle":"2024-07-30T18:07:55.252412Z","shell.execute_reply.started":"2024-07-30T18:07:55.248078Z","shell.execute_reply":"2024-07-30T18:07:55.251489Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"def main(model, optimizer, scheduler=None, system_configuration=SystemConfiguration(),\n         training_configuration=TrainingConfiguration()):\n\n    # system configuration\n    setup_system(system_configuration)\n\n    # batch size\n    batch_size_to_set = training_configuration.batch_size\n    # num_workers\n    num_workers_to_set = training_configuration.num_workers\n    # epochs\n    epoch_num_to_set = training_configuration.epochs_count\n\n    # if GPU is available use training config,\n    # else lowers batch_size, num_workers and epochs count\n    if torch.cuda.is_available():\n        device = \"cuda\"\n    else:\n        device = \"cpu\"\n        batch_size_to_set = 32\n        num_workers_to_set = 4\n\n    \"\"\"\n       #data loader\n    train_dataroot=r\"/kaggle/working/training\"\n    train_dataframe=pd.read_csv('/kaggle/working/train_data.csv')\n    train_dataset=KenyanFood13Dataset(train_dataframe,train_dataroot,is_train=True,transform=train_transform)\n \n    val_dataroot =r\"/kaggle/working/validation\" \n    val_dataframe=pd.read_csv('/kaggle/working/validation_data.csv')\n    val_dataset =KenyanFood13Dataset(val_dataframe,val_dataroot,is_train=True,transform=train_transform)  \n    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=False)\n    \n     \"\"\"   \n        \n    \n\n    # Update training configuration\n    training_configuration = TrainingConfiguration(\n        device=device,\n        batch_size=batch_size_to_set,\n        num_workers=num_workers_to_set\n    )\n\n    # send model to device (GPU/CPU)\n    model.to(training_configuration.device)\n\n    best_loss = torch.tensor(np.inf)\n\n    # epoch train/test loss\n    epoch_train_loss = np.array([])\n    epoch_test_loss = np.array([])\n\n    # epch train/test accuracy\n    epoch_train_acc = np.array([])\n    epoch_test_acc = np.array([])\n\n    # Calculate Initial Test Loss\n    init_val_loss, init_val_accuracy = validate(training_configuration, model, val_loader)\n    print(\"Initial Test Loss : {:.6f}, \\nInitial Test Accuracy : {:.3f}%\\n\".format(init_val_loss,\n                                                                                   init_val_accuracy*100))\n\n    # trainig time measurement\n    t_begin = time.time()\n    for epoch in range(training_configuration.epochs_count):\n\n        # Train\n        train_loss, train_acc = train(training_configuration, model, optimizer, train_loader, epoch)\n\n        epoch_train_loss = np.append(epoch_train_loss, [train_loss])\n\n        epoch_train_acc = np.append(epoch_train_acc, [train_acc])\n\n        elapsed_time = time.time() - t_begin\n        speed_epoch = elapsed_time / (epoch + 1)\n        speed_batch = speed_epoch / len(train_loader)\n        eta = speed_epoch * training_configuration.epochs_count - elapsed_time\n\n        print(\n            \"Elapsed {:.2f}s, {:.2f} s/epoch, {:.2f} s/batch, ets {:.2f}s\".format(\n                elapsed_time, speed_epoch, speed_batch, eta\n            )\n        )\n\n        # Validate\n        if epoch % training_configuration.test_interval == 0:\n            current_loss, current_accuracy = validate(training_configuration, model, val_loader)\n\n            epoch_test_loss = np.append(epoch_test_loss, [current_loss])\n\n            epoch_test_acc = np.append(epoch_test_acc, [current_accuracy])\n\n            if current_loss < best_loss:\n                best_loss = current_loss\n                print('Model Improved. Saving the Model...\\n')\n                save_model(model, device=training_configuration.device)\n\n\n    print(\"Total time: {:.2f}, Best Loss: {:.3f}\".format(time.time() - t_begin, best_loss))\n\n    return model, epoch_train_loss, epoch_train_acc, epoch_test_loss, epoch_test_acc","metadata":{"execution":{"iopub.status.busy":"2024-07-30T18:07:55.306232Z","iopub.execute_input":"2024-07-30T18:07:55.306529Z","iopub.status.idle":"2024-07-30T18:07:55.320180Z","shell.execute_reply.started":"2024-07-30T18:07:55.306505Z","shell.execute_reply":"2024-07-30T18:07:55.319243Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"def get_optimizer_and_scheduler(model):\n    train_config = TrainingConfiguration()\n\n    init_learning_rate = train_config.init_learning_rate\n\n\n    optimizer = optim.Adam(\n        model.parameters(),\n\n        lr =TrainingConfiguration.init_learning_rate,\n        \n    )\n\n    decay_rate = TrainingConfiguration.decay_rate\n\n    lmbda = lambda epoch: 1/(1 + decay_rate * epoch)\n\n    # Scheduler\n    scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lmbda)\n\n    return optimizer, scheduler","metadata":{"execution":{"iopub.status.busy":"2024-07-30T18:07:55.327985Z","iopub.execute_input":"2024-07-30T18:07:55.328273Z","iopub.status.idle":"2024-07-30T18:07:55.333995Z","shell.execute_reply.started":"2024-07-30T18:07:55.328249Z","shell.execute_reply":"2024-07-30T18:07:55.333208Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"markdown","source":"## <font style=\"color:green\">3. Evaluation Metric [10 Points]</font>\n\n**Define methods or classes that will be used in model evaluation. For example, accuracy, f1-score etc.**","metadata":{}},{"cell_type":"code","source":"def plot_loss_accuracy(train_loss, val_loss, train_acc, val_acc, colors,\n                       loss_legend_loc='upper center', acc_legend_loc='upper left',\n                       fig_size=(20, 10), sub_plot1=(1, 2, 1), sub_plot2=(1, 2, 2)):\n\n    plt.rcParams[\"figure.figsize\"] = fig_size\n    fig = plt.figure()\n\n    plt.subplot(sub_plot1[0], sub_plot1[1], sub_plot1[2])\n\n    for i in range(len(train_loss)):\n        x_train = range(len(train_loss[i]))\n        x_val = range(len(val_loss[i]))\n\n        min_train_loss = train_loss[i].min()\n\n        min_val_loss = val_loss[i].min()\n\n        plt.plot(x_train, train_loss[i], linestyle='-', color='tab:{}'.format(colors[i]),\n                 label=\"TRAIN LOSS ({0:.4})\".format(min_train_loss))\n        plt.plot(x_val, val_loss[i], linestyle='--' , color='tab:{}'.format(colors[i]),\n                 label=\"VALID LOSS ({0:.4})\".format(min_val_loss))\n\n    plt.xlabel('epoch no.')\n    plt.ylabel('loss')\n    plt.legend(loc=loss_legend_loc)\n    plt.title('Training and Validation Loss')\n\n    plt.subplot(sub_plot2[0], sub_plot2[1], sub_plot2[2])\n\n    for i in range(len(train_acc)):\n        x_train = range(len(train_acc[i]))\n        x_val = range(len(val_acc[i]))\n\n        max_train_acc = train_acc[i].max()\n\n        max_val_acc = val_acc[i].max()\n\n        plt.plot(x_train, train_acc[i], linestyle='-', color='tab:{}'.format(colors[i]),\n                 label=\"TRAIN ACC ({0:.4})\".format(max_train_acc))\n        plt.plot(x_val, val_acc[i], linestyle='--' , color='tab:{}'.format(colors[i]),\n                 label=\"VALID ACC ({0:.4})\".format(max_val_acc))\n\n    plt.xlabel('epoch no.')\n    plt.ylabel('accuracy')\n    plt.legend(loc=acc_legend_loc)\n    plt.title('Training and Validation Accuracy')\n\n    fig.savefig('sample_loss_acc_plot.png')\n    plt.show()\n\n    return","metadata":{"execution":{"iopub.status.busy":"2024-07-30T18:07:55.363638Z","iopub.execute_input":"2024-07-30T18:07:55.363922Z","iopub.status.idle":"2024-07-30T18:07:55.376179Z","shell.execute_reply.started":"2024-07-30T18:07:55.363901Z","shell.execute_reply":"2024-07-30T18:07:55.375194Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"\nclass MyModel(nn.Module):\n    \n    def __init__(self, dropout=0.15, batch_norm=True):\n        super().__init__()\n\n        # convolution layers\n        \n        self._body = nn.Sequential(\n            nn.Conv2d(in_channels=3, out_channels=100, kernel_size=5, padding=2),\n            nn.BatchNorm2d(100),\n            nn.ReLU(inplace=True),\n\n            nn.Conv2d(in_channels=100, out_channels=80, kernel_size=5, padding=2),\n            nn.BatchNorm2d(80),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2),\n            \n            nn.Conv2d(in_channels=80, out_channels=45, kernel_size=5, padding=2),\n            nn.BatchNorm2d(45),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2),\n            nn.Dropout(dropout),\n            \n            \n            nn.Conv2d(in_channels=45, out_channels=15, kernel_size=5, padding=2),\n            nn.BatchNorm2d(15),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2),\n            nn.Dropout(dropout),\n\n            nn.Conv2d(in_channels=15, out_channels=9, kernel_size=5, padding=2),\n            nn.BatchNorm2d(9),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2),\n            nn.Dropout(dropout),\n            nn.Conv2d(in_channels=9, out_channels=5, kernel_size=5, padding=2),\n            nn.BatchNorm2d(5),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2),\n            nn.Dropout(dropout),\n\n           \n            \n                \n            )\n\n\n        # Fully connected layers\n        self._head = nn.Sequential(\n\n            nn.Linear(in_features=245, out_features=5000),\n            nn.ReLU(inplace=True),\n            nn.Dropout(dropout),\n\n            nn.Linear(in_features=5000, out_features=3000),\n            nn.ReLU(inplace=True),\n            nn.Dropout(dropout),\n\n\n\n\n            nn.Linear(in_features=3000, out_features=1000),\n            nn.ReLU(inplace=True),\n            nn.Dropout(dropout),\n            \n            nn.Linear(in_features=1000, out_features=300),\n            nn.ReLU(inplace=True),\n            nn.Dropout(dropout),\n\n\n            nn.Linear(in_features=300, out_features=13)\n        )\n\n    def forward(self, x):\n        x = self._body(x)\n        x = x.view(x.size()[0], -1)\n        x = self._head(x)\n        return x\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-07-30T18:07:55.400096Z","iopub.execute_input":"2024-07-30T18:07:55.400370Z","iopub.status.idle":"2024-07-30T18:07:55.413843Z","shell.execute_reply.started":"2024-07-30T18:07:55.400347Z","shell.execute_reply":"2024-07-30T18:07:55.412907Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"model = MyModel(0.20, batch_norm=True)\nprint(model)\n\noptimizer, scheduler = get_optimizer_and_scheduler(model)\n\nmodel, train_loss, train_acc, val_loss, val_acc = main(model, optimizer, scheduler)","metadata":{"execution":{"iopub.status.busy":"2024-07-30T18:07:55.422711Z","iopub.execute_input":"2024-07-30T18:07:55.423065Z","iopub.status.idle":"2024-07-30T18:07:56.083392Z","shell.execute_reply.started":"2024-07-30T18:07:55.423035Z","shell.execute_reply":"2024-07-30T18:07:56.081982Z"},"trusted":true},"execution_count":90,"outputs":[{"name":"stdout","text":"MyModel(\n  (_body): Sequential(\n    (0): Conv2d(3, 100, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n    (1): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): Conv2d(100, 80, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n    (4): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): ReLU(inplace=True)\n    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (7): Conv2d(80, 45, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n    (8): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (9): ReLU(inplace=True)\n    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (11): Dropout(p=0.2, inplace=False)\n    (12): Conv2d(45, 15, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n    (13): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (14): ReLU(inplace=True)\n    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (16): Dropout(p=0.2, inplace=False)\n    (17): Conv2d(15, 9, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n    (18): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (19): ReLU(inplace=True)\n    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (21): Dropout(p=0.2, inplace=False)\n    (22): Conv2d(9, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n    (23): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (24): ReLU(inplace=True)\n    (25): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (26): Dropout(p=0.2, inplace=False)\n  )\n  (_head): Sequential(\n    (0): Linear(in_features=245, out_features=5000, bias=True)\n    (1): ReLU(inplace=True)\n    (2): Dropout(p=0.2, inplace=False)\n    (3): Linear(in_features=5000, out_features=3000, bias=True)\n    (4): ReLU(inplace=True)\n    (5): Dropout(p=0.2, inplace=False)\n    (6): Linear(in_features=3000, out_features=1000, bias=True)\n    (7): ReLU(inplace=True)\n    (8): Dropout(p=0.2, inplace=False)\n    (9): Linear(in_features=1000, out_features=300, bias=True)\n    (10): ReLU(inplace=True)\n    (11): Dropout(p=0.2, inplace=False)\n    (12): Linear(in_features=300, out_features=13, bias=True)\n  )\n)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/PIL/Image.py:3240\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3239\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3240\u001b[0m     \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseek\u001b[49m(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   3241\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, io\u001b[38;5;241m.\u001b[39mUnsupportedOperation):\n","\u001b[0;31mAttributeError\u001b[0m: 'numpy.uint64' object has no attribute 'seek'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[90], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(model)\n\u001b[1;32m      4\u001b[0m optimizer, scheduler \u001b[38;5;241m=\u001b[39m get_optimizer_and_scheduler(model)\n\u001b[0;32m----> 6\u001b[0m model, train_loss, train_acc, val_loss, val_acc \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[86], line 60\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(model, optimizer, scheduler, system_configuration, training_configuration)\u001b[0m\n\u001b[1;32m     57\u001b[0m epoch_test_acc \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([])\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Calculate Initial Test Loss\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m init_val_loss, init_val_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_configuration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitial Test Loss : \u001b[39m\u001b[38;5;132;01m{:.6f}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mInitial Test Accuracy : \u001b[39m\u001b[38;5;132;01m{:.3f}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(init_val_loss,\n\u001b[1;32m     62\u001b[0m                                                                                init_val_accuracy\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m))\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# trainig time measurement\u001b[39;00m\n","Cell \u001b[0;32mIn[83], line 10\u001b[0m, in \u001b[0;36mvalidate\u001b[0;34m(train_config, model, test_loader)\u001b[0m\n\u001b[1;32m      8\u001b[0m test_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      9\u001b[0m count_corect_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data, target \u001b[38;5;129;01min\u001b[39;00m val_loader:\n\u001b[1;32m     12\u001b[0m     data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(train_config\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     14\u001b[0m     target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mto(train_config\u001b[38;5;241m.\u001b[39mdevice)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","Cell \u001b[0;32mIn[74], line 34\u001b[0m, in \u001b[0;36mKenyanFood13Dataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m     33\u001b[0m     img_path, label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataframe\u001b[38;5;241m.\u001b[39miloc[idx]\n\u001b[0;32m---> 34\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[1;32m     37\u001b[0m         image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(image)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/PIL/Image.py:3242\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3240\u001b[0m     fp\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   3241\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, io\u001b[38;5;241m.\u001b[39mUnsupportedOperation):\n\u001b[0;32m-> 3242\u001b[0m     fp \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO(\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m())\n\u001b[1;32m   3243\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   3245\u001b[0m prefix \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m16\u001b[39m)\n","\u001b[0;31mAttributeError\u001b[0m: 'numpy.uint64' object has no attribute 'read'"],"ename":"AttributeError","evalue":"'numpy.uint64' object has no attribute 'read'","output_type":"error"}]},{"cell_type":"markdown","source":"## <font style=\"color:green\">4. Train and Validation [5 Points]</font>\n\n\n**Write the methods or classes to be used for training and validation.**","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <font style=\"color:green\">5. Model [5 Points]</font>\n\n**Define your model in this section.**\n\n**You are allowed to use any pre-trained model.**","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <font style=\"color:green\">6. Utils [5 Points]</font>\n\n**Define those methods or classes, which have  not been covered in the above sections.**","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <font style=\"color:green\">7. Experiment [5 Points]</font>\n\n**Choose your optimizer and LR-scheduler and use the above methods and classes to train your model.**","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <font style=\"color:green\">8. TensorBoard Dev Scalars Log Link [5 Points]</font>\n\n**Share your TensorBoard scalars logs link here You can also share (not mandatory) your GitHub link, if you have pushed this project in GitHub.**\n\n\nFor example, [Find Project2 logs here](https://tensorboard.dev/experiment/kMJ4YU0wSNG0IkjrluQ5Dg/#scalars).","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"## <font style=\"color:green\">9. Kaggle Profile Link [50 Points]</font>\n\n**Share your Kaggle profile link  with us here to score , points in  the competition.**\n\n**For full points, you need a minimum accuracy of `75%` on the test data. If accuracy is less than `70%`, you gain  no points for this section.**\n\n\n**Submit `submission.csv` (prediction for images in `test.csv`), in the `Submit Predictions` tab in Kaggle, to get evaluated for  this section.**","metadata":{}}]}