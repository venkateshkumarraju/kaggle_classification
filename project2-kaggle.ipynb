{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":66638,"databundleVersionId":7378729,"sourceType":"competition"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## <font style=\"color:green\">1. Data Loader [10 Points]</font>\n\nIn this section, you have to write a class or methods, which will be used to get training and validation data loader.\n\nYou need to write a custom dataset class to load data.\n\n**Note; There is   no separate validation data. , You will thus have to create your own validation set, by dividing the train data into train and validation data. Usually, we do 80:20 ratio for train and validation, respectively.**\n\n\nFor example:\n\n```python\nclass KenyanFood13Dataset(Dataset):\n    \"\"\"\n    \n    \"\"\"\n    \n    def __init__(self, *args):\n    ....\n    ...\n    \n    def __getitem__(self, idx):\n    ...\n    ...\n    \n\n```\n\n\n```python\ndef get_data(args1, *args):\n    ....\n    ....\n    return train_loader, test_loader\n```","metadata":{}},{"cell_type":"markdown","source":"# <font style=\"color:blue\">Project 2: Kaggle Competition - Classification</font>\n\n#### Maximum Points: 100\n\n<div>\n    <table>\n        <tr><td><h3>Sr. no.</h3></td> <td><h3>Section</h3></td> <td><h3>Points</h3></td> </tr>\n        <tr><td><h3>1</h3></td> <td><h3>Data Loader</h3></td> <td><h3>10</h3></td> </tr>\n        <tr><td><h3>2</h3></td> <td><h3>Configuration</h3></td> <td><h3>5</h3></td> </tr>\n        <tr><td><h3>3</h3></td> <td><h3>Evaluation Metric</h3></td> <td><h3>10</h3></td> </tr>\n        <tr><td><h3>4</h3></td> <td><h3>Train and Validation</h3></td> <td><h3>5</h3></td> </tr>\n        <tr><td><h3>5</h3></td> <td><h3>Model</h3></td> <td><h3>5</h3></td> </tr>\n        <tr><td><h3>6</h3></td> <td><h3>Utils</h3></td> <td><h3>5</h3></td> </tr>\n        <tr><td><h3>7</h3></td> <td><h3>Experiment</h3></td><td><h3>5</h3></td> </tr>\n        <tr><td><h3>8</h3></td> <td><h3>TensorBoard Dev Scalars Log Link</h3></td> <td><h3>5</h3></td> </tr>\n        <tr><td><h3>9</h3></td> <td><h3>Kaggle Profile Link</h3></td> <td><h3>50</h3></td> </tr>\n    </table>\n</div>\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport shutil\nimport os\nimport sys\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom torchvision import transforms\nfrom PIL import Image","metadata":{"execution":{"iopub.status.busy":"2024-09-10T15:10:19.353438Z","iopub.execute_input":"2024-09-10T15:10:19.353806Z","iopub.status.idle":"2024-09-10T15:10:24.655423Z","shell.execute_reply.started":"2024-09-10T15:10:19.353759Z","shell.execute_reply":"2024-09-10T15:10:24.654444Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import torch\ntorch.manual_seed(0)","metadata":{"execution":{"iopub.status.busy":"2024-09-10T15:10:24.656975Z","iopub.execute_input":"2024-09-10T15:10:24.657427Z","iopub.status.idle":"2024-09-10T15:10:24.668587Z","shell.execute_reply.started":"2024-09-10T15:10:24.657392Z","shell.execute_reply":"2024-09-10T15:10:24.667692Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7dab4d84b590>"},"metadata":{}}]},{"cell_type":"code","source":"import torch\nprint(torch.cuda.is_available())","metadata":{"execution":{"iopub.status.busy":"2024-09-10T15:10:24.723748Z","iopub.execute_input":"2024-09-10T15:10:24.724059Z","iopub.status.idle":"2024-09-10T15:10:24.731855Z","shell.execute_reply.started":"2024-09-10T15:10:24.724021Z","shell.execute_reply":"2024-09-10T15:10:24.730979Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"True\n","output_type":"stream"}]},{"cell_type":"code","source":"\n\n# Load your dataset\ndata = pd.read_csv(r'/kaggle/input/opencv-pytorch-classification-project-2/train.csv')\n\n# Define the split ratio (e.g., 80% training and 20% validation)\ntrain_size = 0.8\n\n# Split the data\ntrain_data, validation_data = train_test_split(data, train_size=train_size, random_state=42)\n\n# Save the split datasets into new CSV files\ntrain_data.to_csv('train_data.csv', index=False)\nvalidation_data.to_csv('validation_data.csv', index=False)\n\nprint(len(train_data))\n\nprint(len(validation_data))","metadata":{"execution":{"iopub.status.busy":"2024-09-10T15:10:31.228157Z","iopub.execute_input":"2024-09-10T15:10:31.228560Z","iopub.status.idle":"2024-09-10T15:10:31.277397Z","shell.execute_reply.started":"2024-09-10T15:10:31.228523Z","shell.execute_reply":"2024-09-10T15:10:31.276568Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"5228\n1308\n","output_type":"stream"}]},{"cell_type":"code","source":"#create new directory for training set\nif not os.path.exists('training'):\n    os.mkdir('training')\n\n# Read your train CSV file for lable\nlabels=pd.read_csv(r'/kaggle/working/train_data.csv')\n\n#DataFrame 'labels' with columns 'id' and 'class'\n\n\n# Set the base directory where your images are located\nbase_image_dir = '/kaggle/input/opencv-pytorch-classification-project-2/images/images/'\ndst_dir=r\"/kaggle/working/training\"\n# Iterate over each row in the labels DataFrame\nfor _, row in labels.iterrows():\n    image_id = row['id']\n    class_label = str(row['class'])\n\n    # Construct source and destination paths\n    src_path = os.path.join(base_image_dir, f'{image_id}.jpg')\n    dst_path = os.path.join(dst_dir, class_label, f'{image_id}.jpg')\n\n    try:\n        # Check if the source file exists\n        if os.path.exists(src_path):\n            # Create the destination directory if needed\n            os.makedirs(os.path.dirname(dst_path), exist_ok=True)\n            shutil.copy(src_path, dst_path)\n            print(f\"Successfully copied {src_path} to {dst_path}\")\n        else:\n            print(f\"Source file {src_path} does not exist.\")\n    except Exception as e:\n        print(f\"Error copying {src_path} to {dst_path}: {e}\")\n\nprint(\"All images processed!\")\n\n\n","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create new directory for training set\nif not os.path.exists('validation'):\n    os.mkdir('validation')\n\nval_lables=pd.read_csv(r'/kaggle/working/validation_data.csv')\n#DataFrame 'labels' with columns 'id' and 'class'\n\n\n# Set the base directory where your images are located\nbase_image_dir = '/kaggle/input/opencv-pytorch-classification-project-2/images/images/'\ndst_dir=r\"/kaggle/working/validation\"\n# Iterate over each row in the labels DataFrame\nfor _, row in labels.iterrows():\n    image_id = row['id']\n    class_label = str(row['class'])\n\n    # Construct source and destination paths\n    src_path = os.path.join(base_image_dir, f'{image_id}.jpg')\n    dst_path = os.path.join(dst_dir, class_label, f'{image_id}.jpg')\n\n    try:\n        # Check if the source file exists\n        if os.path.exists(src_path):\n            # Create the destination directory if needed\n            os.makedirs(os.path.dirname(dst_path), exist_ok=True)\n            shutil.copy(src_path, dst_path)\n            print(f\"Successfully copied {src_path} to {dst_path}\")\n        else:\n            print(f\"Source file {src_path} does not exist.\")\n    except Exception as e:\n        print(f\"Error copying {src_path} to {dst_path}: {e}\")\n\nprint(\"All images processed!\")","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read your test CSV file for geting test image set\ntest_img=pd.read_csv(r'/kaggle/input/opencv-pytorch-classification-project-2/test.csv')\n\n#create new directory for test set\nif not os.path.exists('test'):\n    os.mkdir('test')\n# Set the base directory where your images are located\nbase_image_dir = '/kaggle/input/opencv-pytorch-classification-project-2/images/images/'\ntest_dst=r\"/kaggle/working/test\"#destination for test images\n\n# Iterate over each row in the labels DataFrame\nfor _, row in test_img.iterrows():\n    image_id = row['id']\n    \n# Construct source and destination paths\n    src_path = os.path.join(base_image_dir, f'{image_id}.jpg')\n    dst_path = os.path.join(test_dst, f'{image_id}.jpg')\n    \n    try:\n        # Check if the source file exists\n        if os.path.exists(src_path):\n            # Create the destination directory if needed\n            #os.makedirs(os.path.dirname(dst_path), exist_ok=True)\n            shutil.copy(src_path, dst_path)\n            print(f\"Successfully copied {src_path} to {dst_path}\")\n        else:\n            print(f\"Source file {src_path} does not exist.\")\n    except Exception as e:\n        print(f\"Error copying {src_path} to {dst_path}: {e}\")\n\nprint(\"All images processed!\")","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\n\nimport os\nimport time\n\nfrom typing import Iterable\nfrom dataclasses import dataclass\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\n\n\nfrom torchvision import datasets, transforms, models\n\nfrom torch.optim import lr_scheduler\n\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.tensorboard import SummaryWriter\n\nimport pandas as pd\n\nfrom PIL import Image","metadata":{"execution":{"iopub.status.busy":"2024-09-10T15:10:36.195342Z","iopub.execute_input":"2024-09-10T15:10:36.195991Z","iopub.status.idle":"2024-09-10T15:10:48.135554Z","shell.execute_reply.started":"2024-09-10T15:10:36.195951Z","shell.execute_reply":"2024-09-10T15:10:48.134757Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#%load_ext tensorboard\n%reload_ext tensorboard\n\n%tensorboard --logdir=log_resnet18/transfer_learning","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class KenyanFood13Dataset(Dataset):\n    def __init__(self, data, transform=None):\n        super().__init__()\n\n        self.transform = transform\n\n        # initialize the arrays to store the ground truth labels and paths to the images\n        self.data_path = []\n        self.labels = []\n\n        # iterate over the data numpy array\n        for i , (img_path,cls) in enumerate (data):\n            self.data_path.append(img_path)\n            self.labels.append(class_to_id[cls])\n\n\n    def __len__(self):\n        return len(self.data_path)\n\n    def __getitem__(self, idx):\n        # take the data sample by its index\n        img_path = self.data_path[idx]\n\n        # read image\n        img = Image.open(img_path)\n\n        # apply the image augmentations if needed\n        if self.transform:\n            img = self.transform(img)\n\n        # return the image and its associated labels and path\n        target = self.labels[idx]\n\n        return img, target\n\n    def image_path(self, idx):\n        return self.data_path[idx]\n\n    def class_name(self, label):\n        return id_to_class[label]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def image_preprocess_transforms():\n\n    preprocess = transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor()\n        ])\n\n    return preprocess","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def image_common_transforms(mean=(0.5773, 0.4627, 0.3468), std=(0.2387, 0.2470, 0.2473)):\n    preprocess = image_preprocess_transforms()\n\n    common_transforms = transforms.Compose([\n        preprocess,\n        transforms.Normalize(mean, std)\n    ])\n\n    return common_transforms","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <font style=\"color:green\">2. Configuration [5 Points]</font>\n\n**Define your configuration here.**\n\nFor example:\n\n\n```python\n@dataclass\nclass TrainingConfiguration:\n    '''\n    Describes configuration of the training process\n    '''\n    batch_size: int = 10 \n    epochs_count: int = 50  \n    init_learning_rate: float = 0.1  # initial learning rate for lr scheduler\n    log_interval: int = 5  \n    test_interval: int = 1  \n    data_root: str = \"/kaggle/input/opencv-pytorch-classification-project-2/\" \n    num_workers: int = 2  \n    device: str = 'cuda'  \n    \n```","metadata":{}},{"cell_type":"markdown","source":"## <font style=\"color:green\">3. Evaluation Metric [10 Points]</font>\n\n**Define methods or classes that will be used in model evaluation. For example, accuracy, f1-score etc.**","metadata":{}},{"cell_type":"markdown","source":"## <font style=\"color:green\">4. Train and Validation [5 Points]</font>\n\n\n**Write the methods or classes to be used for training and validation.**","metadata":{}},{"cell_type":"markdown","source":"## <font style=\"color:green\">5. Model [5 Points]</font>\n\n**Define your model in this section.**\n\n**You are allowed to use any pre-trained model.**","metadata":{}},{"cell_type":"markdown","source":"## <font style=\"color:green\">6. Utils [5 Points]</font>\n\n**Define those methods or classes, which have  not been covered in the above sections.**","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <font style=\"color:green\">7. Experiment [5 Points]</font>\n\n**Choose your optimizer and LR-scheduler and use the above methods and classes to train your model.**","metadata":{}},{"cell_type":"markdown","source":"## <font style=\"color:green\">9. Kaggle Profile Link [50 Points]</font>\n\n**Share your Kaggle profile link  with us here to score , points in  the competition.**\n\n**For full points, you need a minimum accuracy of `75%` on the test data. If accuracy is less than `70%`, you gain  no points for this section.**\n\n\n**Submit `submission.csv` (prediction for images in `test.csv`), in the `Submit Predictions` tab in Kaggle, to get evaluated for  this section.**","metadata":{"execution":{"iopub.status.busy":"2024-09-03T19:49:19.222719Z","iopub.execute_input":"2024-09-03T19:49:19.223252Z","iopub.status.idle":"2024-09-03T19:49:19.232418Z","shell.execute_reply.started":"2024-09-03T19:49:19.223197Z","shell.execute_reply":"2024-09-03T19:49:19.230774Z"}}},{"cell_type":"markdown","source":"## <font style=\"color:green\">8. TensorBoard Dev Scalars Log Link [5 Points]</font>\n\n**Share your TensorBoard scalars logs link here You can also share (not mandatory) your GitHub link, if you have pushed this project in GitHub.**\n\n\nFor example, [Find Project2 logs here](https://tensorboard.dev/experiment/kMJ4YU0wSNG0IkjrluQ5Dg/#scalars).","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}}]}